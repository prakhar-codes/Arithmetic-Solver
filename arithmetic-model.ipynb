{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tensorflow.keras import layers, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Step 1: Prepare your dataset\n",
    "train_dir = \"Training/train\"  # Update with the path to the training folder\n",
    "eval_dir = \"Training/eval\"  # Update with the path to the validation folder\n",
    "classes = sorted(os.listdir(train_dir))\n",
    "num_classes = len(classes)\n",
    "image_size = (28, 28)  # Adjust the image size as per your dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Load and preprocess the dataset\n",
    "def load_images_from_folder(folder):\n",
    "    images = []\n",
    "    labels = []\n",
    "    for i, cls in enumerate(classes):\n",
    "        cls_dir = os.path.join(folder, cls)\n",
    "        for image_name in os.listdir(cls_dir):\n",
    "            image = cv2.imread(os.path.join(cls_dir, image_name), cv2.IMREAD_GRAYSCALE)\n",
    "            image = cv2.resize(image, image_size)\n",
    "            images.append(image)\n",
    "            labels.append(i)\n",
    "    return images, labels\n",
    "\n",
    "train_images, train_labels = load_images_from_folder(train_dir)\n",
    "eval_images, eval_labels = load_images_from_folder(eval_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the images and labels to numpy arrays\n",
    "train_images = np.array(train_images) / 255.0  # Normalize pixel values\n",
    "train_labels = np.array(train_labels)\n",
    "eval_images = np.array(eval_images) / 255.0  # Normalize pixel values\n",
    "eval_labels = np.array(eval_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Build your CNN model\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(image_size[0], image_size[1], 1)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(image_size[0], image_size[1], 1)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(num_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "69/69 [==============================] - 1s 12ms/step - loss: 0.7564 - accuracy: 0.7273 - val_loss: 0.3025 - val_accuracy: 0.8924\n",
      "Epoch 2/50\n",
      "69/69 [==============================] - 1s 9ms/step - loss: 0.2529 - accuracy: 0.9156 - val_loss: 0.1416 - val_accuracy: 0.9778\n",
      "Epoch 3/50\n",
      "69/69 [==============================] - 1s 9ms/step - loss: 0.1422 - accuracy: 0.9580 - val_loss: 0.0962 - val_accuracy: 0.9715\n",
      "Epoch 4/50\n",
      "69/69 [==============================] - 1s 9ms/step - loss: 0.0966 - accuracy: 0.9722 - val_loss: 0.0611 - val_accuracy: 0.9810\n",
      "Epoch 5/50\n",
      "69/69 [==============================] - 1s 9ms/step - loss: 0.0740 - accuracy: 0.9754 - val_loss: 0.0686 - val_accuracy: 0.9873\n",
      "Epoch 6/50\n",
      "69/69 [==============================] - 1s 9ms/step - loss: 0.0588 - accuracy: 0.9845 - val_loss: 0.0455 - val_accuracy: 0.9842\n",
      "Epoch 7/50\n",
      "69/69 [==============================] - 1s 10ms/step - loss: 0.0493 - accuracy: 0.9863 - val_loss: 0.0296 - val_accuracy: 0.9873\n",
      "Epoch 8/50\n",
      "69/69 [==============================] - 1s 10ms/step - loss: 0.0417 - accuracy: 0.9872 - val_loss: 0.0569 - val_accuracy: 0.9842\n",
      "Epoch 9/50\n",
      "69/69 [==============================] - 1s 10ms/step - loss: 0.0352 - accuracy: 0.9881 - val_loss: 0.0259 - val_accuracy: 1.0000\n",
      "Epoch 10/50\n",
      "69/69 [==============================] - 1s 10ms/step - loss: 0.0321 - accuracy: 0.9904 - val_loss: 0.0417 - val_accuracy: 0.9905\n",
      "Epoch 11/50\n",
      "69/69 [==============================] - 1s 10ms/step - loss: 0.0303 - accuracy: 0.9918 - val_loss: 0.0491 - val_accuracy: 0.9842\n",
      "Epoch 12/50\n",
      "69/69 [==============================] - 1s 10ms/step - loss: 0.0278 - accuracy: 0.9922 - val_loss: 0.0493 - val_accuracy: 0.9873\n",
      "Epoch 13/50\n",
      "69/69 [==============================] - 1s 10ms/step - loss: 0.0196 - accuracy: 0.9964 - val_loss: 0.0568 - val_accuracy: 0.9842\n",
      "Epoch 14/50\n",
      "69/69 [==============================] - 1s 10ms/step - loss: 0.0259 - accuracy: 0.9936 - val_loss: 0.0692 - val_accuracy: 0.9684\n",
      "Epoch 15/50\n",
      "69/69 [==============================] - 1s 10ms/step - loss: 0.0176 - accuracy: 0.9964 - val_loss: 0.0315 - val_accuracy: 0.9937\n",
      "Epoch 16/50\n",
      "69/69 [==============================] - 1s 11ms/step - loss: 0.0152 - accuracy: 0.9964 - val_loss: 0.1043 - val_accuracy: 0.9589\n",
      "Epoch 17/50\n",
      "69/69 [==============================] - 1s 10ms/step - loss: 0.0167 - accuracy: 0.9964 - val_loss: 0.0347 - val_accuracy: 0.9905\n",
      "Epoch 18/50\n",
      "69/69 [==============================] - 1s 10ms/step - loss: 0.0085 - accuracy: 0.9991 - val_loss: 0.0531 - val_accuracy: 0.9905\n",
      "Epoch 19/50\n",
      "69/69 [==============================] - 1s 10ms/step - loss: 0.0099 - accuracy: 0.9973 - val_loss: 0.0265 - val_accuracy: 0.9905\n",
      "Epoch 20/50\n",
      "69/69 [==============================] - 1s 11ms/step - loss: 0.0077 - accuracy: 0.9991 - val_loss: 0.0405 - val_accuracy: 0.9905\n",
      "Epoch 21/50\n",
      "69/69 [==============================] - 1s 10ms/step - loss: 0.0107 - accuracy: 0.9973 - val_loss: 0.1123 - val_accuracy: 0.9652\n",
      "Epoch 22/50\n",
      "69/69 [==============================] - 1s 10ms/step - loss: 0.0156 - accuracy: 0.9954 - val_loss: 0.0548 - val_accuracy: 0.9810\n",
      "Epoch 23/50\n",
      "69/69 [==============================] - 1s 10ms/step - loss: 0.0200 - accuracy: 0.9945 - val_loss: 0.0439 - val_accuracy: 0.9842\n",
      "Epoch 24/50\n",
      "69/69 [==============================] - 1s 10ms/step - loss: 0.0064 - accuracy: 0.9991 - val_loss: 0.0382 - val_accuracy: 0.9842\n",
      "Epoch 25/50\n",
      "69/69 [==============================] - 1s 10ms/step - loss: 0.0058 - accuracy: 0.9986 - val_loss: 0.0346 - val_accuracy: 0.9905\n",
      "Epoch 26/50\n",
      "69/69 [==============================] - 1s 9ms/step - loss: 0.0037 - accuracy: 0.9995 - val_loss: 0.0195 - val_accuracy: 0.9905\n",
      "Epoch 27/50\n",
      "69/69 [==============================] - 1s 9ms/step - loss: 0.0030 - accuracy: 0.9995 - val_loss: 0.0179 - val_accuracy: 0.9905\n",
      "Epoch 28/50\n",
      "69/69 [==============================] - 1s 9ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.0227 - val_accuracy: 0.9905\n",
      "Epoch 29/50\n",
      "69/69 [==============================] - 1s 9ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.0179 - val_accuracy: 0.9905\n",
      "Epoch 30/50\n",
      "69/69 [==============================] - 1s 9ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0175 - val_accuracy: 0.9905\n",
      "Epoch 31/50\n",
      "69/69 [==============================] - 1s 9ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0164 - val_accuracy: 0.9937\n",
      "Epoch 32/50\n",
      "69/69 [==============================] - 1s 9ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0248 - val_accuracy: 0.9905\n",
      "Epoch 33/50\n",
      "69/69 [==============================] - 1s 9ms/step - loss: 0.0013 - accuracy: 0.9995 - val_loss: 0.0235 - val_accuracy: 0.9905\n",
      "Epoch 34/50\n",
      "69/69 [==============================] - 1s 10ms/step - loss: 9.5032e-04 - accuracy: 1.0000 - val_loss: 0.0243 - val_accuracy: 0.9905\n",
      "Epoch 35/50\n",
      "69/69 [==============================] - 1s 9ms/step - loss: 6.6883e-04 - accuracy: 1.0000 - val_loss: 0.0218 - val_accuracy: 0.9905\n",
      "Epoch 36/50\n",
      "69/69 [==============================] - 1s 9ms/step - loss: 5.8511e-04 - accuracy: 1.0000 - val_loss: 0.0203 - val_accuracy: 0.9905\n",
      "Epoch 37/50\n",
      "69/69 [==============================] - 1s 9ms/step - loss: 6.9151e-04 - accuracy: 1.0000 - val_loss: 0.0229 - val_accuracy: 0.9905\n",
      "Epoch 38/50\n",
      "69/69 [==============================] - 1s 9ms/step - loss: 6.4305e-04 - accuracy: 1.0000 - val_loss: 0.0270 - val_accuracy: 0.9905\n",
      "Epoch 39/50\n",
      "69/69 [==============================] - 1s 9ms/step - loss: 5.7301e-04 - accuracy: 1.0000 - val_loss: 0.0322 - val_accuracy: 0.9905\n",
      "Epoch 40/50\n",
      "69/69 [==============================] - 1s 9ms/step - loss: 4.5673e-04 - accuracy: 1.0000 - val_loss: 0.0279 - val_accuracy: 0.9905\n",
      "Epoch 41/50\n",
      "69/69 [==============================] - 1s 9ms/step - loss: 3.9625e-04 - accuracy: 1.0000 - val_loss: 0.0296 - val_accuracy: 0.9905\n",
      "Epoch 42/50\n",
      "69/69 [==============================] - 1s 9ms/step - loss: 3.3532e-04 - accuracy: 1.0000 - val_loss: 0.0273 - val_accuracy: 0.9905\n",
      "Epoch 43/50\n",
      "69/69 [==============================] - 1s 10ms/step - loss: 3.5152e-04 - accuracy: 1.0000 - val_loss: 0.0357 - val_accuracy: 0.9905\n",
      "Epoch 44/50\n",
      "69/69 [==============================] - 1s 10ms/step - loss: 3.9197e-04 - accuracy: 1.0000 - val_loss: 0.0311 - val_accuracy: 0.9905\n",
      "Epoch 45/50\n",
      "69/69 [==============================] - 1s 9ms/step - loss: 3.2293e-04 - accuracy: 1.0000 - val_loss: 0.0473 - val_accuracy: 0.9905\n",
      "Epoch 46/50\n",
      "69/69 [==============================] - 1s 10ms/step - loss: 2.9472e-04 - accuracy: 1.0000 - val_loss: 0.0288 - val_accuracy: 0.9905\n",
      "Epoch 47/50\n",
      "69/69 [==============================] - 1s 10ms/step - loss: 2.5284e-04 - accuracy: 1.0000 - val_loss: 0.0431 - val_accuracy: 0.9905\n",
      "Epoch 48/50\n",
      "69/69 [==============================] - 1s 10ms/step - loss: 2.6309e-04 - accuracy: 1.0000 - val_loss: 0.0343 - val_accuracy: 0.9905\n",
      "Epoch 49/50\n",
      "69/69 [==============================] - 1s 11ms/step - loss: 2.2987e-04 - accuracy: 1.0000 - val_loss: 0.0199 - val_accuracy: 0.9905\n",
      "Epoch 50/50\n",
      "69/69 [==============================] - 1s 10ms/step - loss: 2.1721e-04 - accuracy: 1.0000 - val_loss: 0.0236 - val_accuracy: 0.9905\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x21c26e6a610>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 5: Compile and train your model\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(train_images[..., np.newaxis], train_labels, epochs=50, validation_data=(eval_images[..., np.newaxis], eval_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0236 - accuracy: 0.9905\n",
      "Validation accuracy: 0.9905063509941101\n"
     ]
    }
   ],
   "source": [
    "# Step 6: Evaluate your model\n",
    "test_loss, test_acc = model.evaluate(eval_images[..., np.newaxis], eval_labels)\n",
    "print(\"Validation accuracy:\", test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"arithmetic_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 6ms/step\n"
     ]
    }
   ],
   "source": [
    "# Step 7: Make predictions\n",
    "predictions = model.predict(eval_images[..., np.newaxis])\n",
    "predicted_labels = np.argmax(predictions, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 60ms/step\n",
      "/\n"
     ]
    }
   ],
   "source": [
    "# Load and preprocess the image\n",
    "image_path = \"single_symbol.png\"  # Update with the path to your image\n",
    "image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "image = cv2.resize(image, (28, 28))  # Resize the image as per your model's input size\n",
    "\n",
    "# Normalize and reshape the image\n",
    "image = np.reshape(image, (1, 28, 28, 1))  # Reshape to match the input shape of the model\n",
    "\n",
    "# Make the prediction\n",
    "prediction = model.predict(image)\n",
    "predicted_label = np.argmax(prediction)\n",
    "\n",
    "predicted_symbol = None\n",
    "if(predicted_label==0) : predicted_symbol = '/'\n",
    "elif (predicted_label==1) : predicted_symbol = '-'\n",
    "elif (predicted_label==2) : predicted_symbol = '+'\n",
    "elif (predicted_label==3) : predicted_symbol = '*'\n",
    "\n",
    "# Print the predicted label\n",
    "print(predicted_symbol)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
